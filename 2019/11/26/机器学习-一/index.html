<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="机器学习<一>：绪言"><meta name="keywords" content="Machine Learning, 统计学习方法与西瓜书, 天道宫"><link rel="alternate" href="/default" title="天道宫"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="http://afrunk.github.io/2019/11/26/机器学习-一/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css"><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true,"latex":true};
</script>

    <title>机器学习<一>：绪言 - 天道宫</一></title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">天道宫</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">Home
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">Archivew
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">天道宫</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            Archivew
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            Tags
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            Categories
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            About
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">机器学习<一>：绪言
        </一></h1>

      <div class="post-meta">
        <span class="post-time">
          2019-11-26
        </span><span class="post-category">
            <a href="/categories/Machine-Learning-Course-Notes/">Machine Learning Course & Notes</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、绪言"><span class="toc-text">一、绪言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-基本术语"><span class="toc-text">1.1 基本术语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-分类、回归、聚类"><span class="toc-text">1.2 分类、回归、聚类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-监督学习和无监督学习"><span class="toc-text">1.3 监督学习和无监督学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-假设空间和版本空间"><span class="toc-text">1.4 假设空间和版本空间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-归纳偏好"><span class="toc-text">1.5 归纳偏好</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-如何引导算法确立正确的偏好"><span class="toc-text">A 如何引导算法确立正确的偏好</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-注意NFT定理的前提"><span class="toc-text">B 注意NFT定理的前提</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-发展历程"><span class="toc-text">1.6 发展历程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-应用现状"><span class="toc-text">1.7 应用现状</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-机器学习的应用领域："><span class="toc-text">A 机器学习的应用领域：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-机器学习与数据挖掘的关系"><span class="toc-text">B 机器学习与数据挖掘的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-机器学习的不为人知的优点"><span class="toc-text">C 机器学习的不为人知的优点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-推荐读物和课后习题"><span class="toc-text">1.8 推荐读物和课后习题</span></a></li></ol></li></ol>
    </div>
  </div><div class="post-content"><p>机器学习现在已经发展成为了一个相当大的学科领域，读者想要更好的学习机器学习仅仅学习本书是远远不够的！第一章节大概介绍了一些基本概念和机器学习的大致发展过程，比起网上的很多Mooc确实强上不少，深入浅出，娓娓道来，让人印象深刻的同时反思机器学习的发展状况到底是否还适合19年的我去学习。</p>
<a id="more"></a>
<p>傍晚小街路面上沁出微雨后的湿润，和煦的细风吹来，抬头看着天边的晚霞，嗯，明天又是一个好天气。走到水果摊旁，挑了个根底蜷缩、敲起来声音浑浊的青绿西瓜，一边满心期待着皮薄肉厚瓤甜的爽落感，一边愉快地想着，这学期狠下功夫，基本概念弄得清清楚楚明明白白，算法作业也是信手捏来，这门课成绩一定查不了！</p>
<h1 id="一、绪言"><a href="#一、绪言" class="headerlink" title="一、绪言"></a>一、绪言</h1><p>机器学习致力于研究如何通过计算的手段，利用经验和改善系统自身的性能。在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，即“学习算法”（learning algorithm）。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供相应的判断。</p>
<p><strong>如果说计算机科学是研究关于算法的学问，那么类似的，可以说机器学习是研究关于学习算法的学问。</strong>更形式化的定义：假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T中任务上获得了性能改善，则我们就说关于T和P，该程序对E进行了学习。</p>
<p>本书用“模型”泛指从数据中学到的结果，有文献用“模型”指全局性结果（例如一颗决策树），而用“模式”指局部性结果（例如一条规则）。</p>
<h2 id="1-1-基本术语"><a href="#1-1-基本术语" class="headerlink" title="1.1 基本术语"></a>1.1 基本术语</h2><ul>
<li>data set：数据集</li>
<li>sample：样本</li>
<li>feature：特征</li>
<li>attritube space：属性空间</li>
<li>feature vector：特征向量</li>
<li>dimensionality：维数</li>
<li>classification:分类</li>
<li>regression:回归</li>
<li>training data:训练集</li>
<li>hypothesis:真实 潜在规则自身</li>
<li>lable：标记 </li>
<li>testing sample：测试样本</li>
<li>clustering：聚类</li>
<li>cluster：簇</li>
<li>supervised learning：监督学习</li>
<li>unsupervised learning：无监督学习</li>
<li>generalization：泛化</li>
<li>distribution：分布</li>
<li>independent and identically distributed：独立同分布</li>
<li>induction：归纳</li>
<li>deduction：演绎</li>
<li>concept：概率</li>
<li>inductive learning：归纳学习</li>
<li>specialization：特化</li>
</ul>
<p>要进行机器学习，先要有数据，假定我们收集了一批关于西瓜的数据，例如：(色泽=青绿；根蒂=硬挺；敲声=清脆)，(色泽=乌黑；根蒂=稍蜷；敲声=沉闷)，(色泽=浅白；根蒂=硬挺；敲声=清脆)，····,每对括号内是一条记录，“=”意思是“取值为”。</p>
<p>这组记录的集合称为一个 <strong>“数据集”（data set）</strong>，其中每条记录是关于一个时间或一个对象（这里是一个西瓜）的描述，称为一个<strong>示例（instance）或样本（sample）</strong>。反映事件或对象在某方面的表现或性质的事项，例如“色泽”、“根蒂”、“敲声”，称为<strong>属性（attribute）或“特征”（feature）</strong>；属性上的取值，例如 青绿、乌黑称为属性值（attribute value）。<strong>属性张成的空间称为属性空间（attribute space）\样本空间（sample space）或输入空间</strong>。例如我们把色泽、根蒂、敲声作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置，由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个<strong>特征向量（feature vector)</strong>.</p>
<p>一般地，令 $D={x_1,x_2,x_3,···,x_m}$ 表示包含m个示例的数据集，每个示例由d个属性描述（例如上面的西瓜数据使用了3个属性），则每个示例由 d 个属性描述（例如上面的西瓜数据使用了3个属性），则每个示例 $ x_i = (x_i1;x_i2;···;x_id)$  是d维样本空间 X 中的一个向量，$x_i \in X$,其中 $X_ij $ 是 $x_i$ 在第 j 个属性上的取值，d称为样本 $x_i$的 <strong>维数 （dimensionality）</strong>。</p>
<h2 id="1-2-分类、回归、聚类"><a href="#1-2-分类、回归、聚类" class="headerlink" title="1.2 分类、回归、聚类"></a>1.2 分类、回归、聚类</h2><p>如果希望学得一个能帮助我们判断没刨开的是不是好瓜的模型，仅有前面的示例数据显然是不够的，要建立这样的关于 Prediction（预测）的模型，我们需获得训练样本的结果信息，例如：“（（色泽=青绿，根蒂=蜷缩，敲声=浑浊），好瓜）”。这里关于示例结果的信息，例如，好瓜，称为 Lable(标记)，拥有了标记信息的示例，称为样例（example），一般的，用$（X_i,y_i）$ 表示第 i 个样例，其中$y_i \in Y $ 是示例 $ x_i$ 的标记， Y是所有标记的集合，亦称为 Label space (标记空间) 或 输出空间。</p>
<ul>
<li><strong>分类 classification</strong> ：若我们欲预测的是离散值，例如“好瓜”、“坏瓜”。一般地，预测任务是希望通过对训练集 ${(x_1,y_1),(x_2,y_2),···,(x_m,y_m)}$ 进行学习，建立一个从输入空间 X到输出空间 Y 的映射 $f:X \to Y$<ol>
<li>对只涉及两个类别的“二分类” binary classification 任务，通常称其中一个类为 “正类” positive class,另一个类为“反类” negative class。对二分类任务，通常令 $ Y={-1,+1} 或 {0,1}$。</li>
<li>对涉及多个类别时，则称为“多分类” multi-class classification 任务。对多分类任务，$ \vert Y \vert &gt; 2$;对回归任务，$ y= R,R为实数集$。</li>
</ol>
</li>
<li><strong>回归 regression</strong> : 若我们预测是连续值，例如西瓜成熟度0.95、0.37。</li>
</ul>
<p>学得模型后，使用其进行预测的过程称为“测试”（testing），被预测的样本称为“测试样本”（testing sample）。例如在学得 $f$ 后，对测试例 $x$，可得到其预测标记 $y= f(x)$。</p>
<ul>
<li><strong>聚类 clustering</strong> ：将训练集中的西瓜分为若干组，每组称为一个 簇（cluster），这些自动形成的簇可能对应一些潜在的概念划分，例如 浅色瓜、深色瓜，甚至本地瓜、外地瓜，这样子的学习过程有助于我们了解数据内在的规律，能为更深入地分析数据建立基础，需说明的是，在聚类学习中，浅色瓜、本地瓜这样的概念我们事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。</li>
</ul>
<h2 id="1-3-监督学习和无监督学习"><a href="#1-3-监督学习和无监督学习" class="headerlink" title="1.3 监督学习和无监督学习"></a>1.3 监督学习和无监督学习</h2><p>根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：监督学习（supervised learning）和无监督学习(unsupervised learning)，分类和回归是前者的代表，而聚类则是后者的代表。</p>
<blockquote>
<p>需要注意的是，机器学习的目标是使学得的模型能很好地适用于新样本，而不是仅仅在训练样本上工作得很好；即便对聚类这样子的无监督学习任务，我们也希望学得的簇划分适用于没在训练集中出现的样本，学得模型适用于新样本的能力，称为 泛化 （gengralization）能力。尽管训练集通常只是样本空间的一个很小的采样，我们仍希望它嫩很好反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作得很好。</p>
</blockquote>
<p>通常假设样本空间中全体样本服从一个未知分布 （distribution）$ D $，我们获得的每个样本都是独立地从这个分布上采样获得，即 <strong>独立同分布（independent and identically distributed 简称 i.i.d）</strong>，一般而言，训练样本越多，我们得到的关于 $D$的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。</p>
<h2 id="1-4-假设空间和版本空间"><a href="#1-4-假设空间和版本空间" class="headerlink" title="1.4 假设空间和版本空间"></a>1.4 假设空间和版本空间</h2><p>归纳（induction）和演绎（deduction）是科学推理的两大基本手段，前者是从特殊到一般的泛化（generalization)过程，即从具体的事实归结出一般性规律，后者则是从一般到特殊的特化（specialization)过程，即从基础原理推演出具体状况。例如在数学公里系统中，基于一组公理和推理规则推导出与之相洽的定理，这是演绎；而从样例中学习，显然是一个归纳的过程，因此亦称为归纳学习（inductive learning）。</p>
<p><strong>归纳学习</strong>：</p>
<pre><code>- 狭义：要求从训练数据中学得概率（concept)，因此亦被称为概念学习或概念形成。因为技术实现较难，现在的大多数技术是产生黑箱模型，有所了解有助于理解机器学习的一些基础思想。
- 广义：相当于从样例中学习
</code></pre><p><strong>西瓜问题的假设空间</strong>：可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假设、和（或）反例一致的假设，最终将会获得与训练集一致（即对所有训练样本能给进行正确判断）的假设，这就是我们学得的结果。</p>
<p><img src="1.png" alt="西瓜问题的假设空间"></p>
<p><strong>西瓜问题的版本空间</strong>：需要注意的是，现实问题中我们常面临很大的假设空间，学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的假设集合，称之为 版本空间。</p>
<p><img src="2.png" alt="西瓜问题的假设空间"></p>
<h2 id="1-5-归纳偏好"><a href="#1-5-归纳偏好" class="headerlink" title="1.5 归纳偏好"></a>1.5 归纳偏好</h2><p>如果有一个训练样本满足上述三个假设，那么哪一个假设更好呢？对于一个具体的学习算法来说，必须产生一个模型。这时，学习算法本身的偏好就会起到关键的作用。若我们的算法喜欢<strong>_尽可能特殊_</strong> 的模型：<strong>好瓜-（色泽=*）^(根蒂=蜷缩)^(敲声=浑浊)</strong>,若我们的算法喜欢 <strong>_尽可能一般_</strong> 的模型：<strong>好瓜-（色泽=*）^(根蒂=蜷缩)^(敲声=*)</strong>，机器学习算法在学习过程中对某种类型假设的偏好，称为 <strong>归纳偏好</strong> 。</p>
<p>任何一个有效的机器学习算法必有其归纳偏好，否则它被假设空间中看似在训练集上等效的假设所迷惑，而无法产生确定的学习结果。</p>
<blockquote>
<p>归纳偏好的作用在图1.3这个回归学习图中可能更直观，这里的每个训练样本是图中的一个点（x,y），要学得一个与训练集一直的模型，相当于找到一条穿过所有训练样本点的曲线，显然，对有限个样本点组成的训练集，存在着很多条曲线与其一致，我们的算法必须有某种偏好，才能产出它认为正确的模型。例如若认为相似的样本应有相似的输出（例如在各种属性上都很相像的西瓜，成熟程度应该比较接近），则对应的学习算法可能偏好图1.3中比较平滑的曲线A而不是比较崎岖的曲线B。</p>
</blockquote>
<p><img src="3.png" alt="存在多条曲线与有限样本训练集一致"></p>
<h3 id="A-如何引导算法确立正确的偏好"><a href="#A-如何引导算法确立正确的偏好" class="headerlink" title="A 如何引导算法确立正确的偏好"></a>A 如何引导算法确立正确的偏好</h3><p>Occam`s razor 是一种常用的、自然科学研究中最基本的原则，<strong>即 若有多个假设与观察一致，则选最简单的那个</strong>，如果采用这个原则，并且假设我们认为更平滑意味着更简单，则在图中我们会自然地偏好平滑的曲线A.</p>
<blockquote>
<p>事实上，归纳偏好对应了学习算法本身所做出的关于 什么样的模型更好 假设，在具体的现实问题中，这个假设是否成立，集算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好性能。</p>
</blockquote>
<p>但是如果我们采取的是 描述简单性来选择算法的话，会出现一种情况。会不会在某种情况下，B比A的泛化能力更强？这是完全有可能的，而且根据公式推导我们会得到一个结论：<strong>NFT，No Free Lunch Theorem 没有免费午餐定理</strong>，在任何一个算法中，对于任意两个学习算法不管是A还是B他们的总误差与学习算法是无关的。</p>
<p><img src="4.png" alt="NFT定理的推导过程"></p>
<h3 id="B-注意NFT定理的前提"><a href="#B-注意NFT定理的前提" class="headerlink" title="B 注意NFT定理的前提"></a>B 注意NFT定理的前提</h3><p>NFL定理有一个重要前提：所有问题出现的机会相同、或所有问题同等重要，但实际情况并不是这样。很多时候，我们只关注自己正在试图解决的问题（例如某个具体应用任务），希望为它找到一个解决方案，至于这个解决方案在别的问题、甚至相似的问题上是否为好方案，我们并不关心。</p>
<p><img src="5.png" alt="NFT定理的推导过程"></p>
<p><strong>所以 NFT定理最主要的寓意就是让我们清楚的认识到，脱离具体问题，空泛地谈论 什么学习算法更好 毫无意义，因为考虑所有潜在的问题，则所有学习算法都一样好，要谈论算法的相对优劣，必须要针对具体的学习问题；在某些问题上表现好的学习算法，在另一些问题上却可能不尽人意，学习算法自身的归纳偏好于问题是否相配，往往会起到绝对性的作用</strong></p>
<h2 id="1-6-发展历程"><a href="#1-6-发展历程" class="headerlink" title="1.6 发展历程"></a>1.6 发展历程</h2><p>机器学习是人工智能（artificial intelligence）研究发展到一定阶段的必然产物。</p>
<ol>
<li>二十世纪五十年代到七十年代初：人工智能研究处于推理期</li>
<li>二十世纪七十年代：LLP</li>
<li>二十世纪八十年代：样例学习<br> a. 决策树:典型的决策树学习以信息论为基础，以信息熵的最小化为目标，直接模拟了人类对概念进行判定的树形流程。<br> b. 基于逻辑的学习</li>
<li>二十世纪九十年代：<br> a. 神经网络的连接主义学习：BP算法作为被应用最广泛的机器学习算法一直，它的推广使得在很多现实问题上发挥作用。连接主义学习的最大局限是其 <strong>试错性</strong>，简单地说，其学习过程涉及大量参数，而参数的设置缺乏理论指导，主要靠手工调参；夸张一点说，参数调节上失之毫厘，学习结果可能谬之千里。<br> b. 统计学习（statistical learning)闪亮登场并迅速占据主流舞台，代表性技术是支持向量机（Support vector machine，SVM）,以及更一般的核方法（kernel methods）。</li>
<li>二十一世纪初：<br> a. 连接主义学习以深度学习名义卷土重来：深度学习狭义上讲就是很多层的神经网络，在若干测试和竞赛中，尤其涉及语音、图像等复杂对象的应用中，深度学习技巧取得了优越性能。<strong>以往机器学习技术在应用中要取得好性能，对使用者的要求较高；而深度学习技术涉及的模型复杂度非常高，以至于只要下功夫调参，把参数调节好，性能往往就好。深度学习虽然缺乏严格的理论基础，但它显著降低了机器学习应用者的门槛，为机器学习技术走向工程实践带来了便利</strong><blockquote>
<p>深度学习的缺点：数据大了、计算能力强了。深度学习模型拥有大量参数，若数据样本少，则很容易过拟合；如此复杂的模型、如此大的数据样本，若缺乏强力计算设备，根本无法求解。随着大数据时代的到来，数据存储与计算设备都有了大发展，才使得连接主义学习技术焕发又一春。深度学习此时的状况，与彼时的神经网络何其相似。</p>
</blockquote>
</li>
</ol>
<h2 id="1-7-应用现状"><a href="#1-7-应用现状" class="headerlink" title="1.7 应用现状"></a>1.7 应用现状</h2><p>过去二十年中，人类收集、存储、传输、处理数据的能力取得飞速提升，人类社会的各个角落都积累了大量数据，亟需能有效对数据进行分析利用的计算机算法，而机器学习恰顺应了大时代的这个迫切需求，因此该学科领域很自然取得巨大发展、受到广泛关注。</p>
<blockquote>
<p>但是为什么到了19年之后唱衰机器学习的人在知乎上越来越多，但是留学生学习的内容却在各个方面都需要使用机器学习来实现呢？ 这是一个值得我去思考的问题，如果机器学习真的不是一个蓝海，而是即将成为红海，那么下一个风口又是什么？</p>
</blockquote>
<h3 id="A-机器学习的应用领域："><a href="#A-机器学习的应用领域：" class="headerlink" title="A 机器学习的应用领域："></a>A 机器学习的应用领域：</h3><ol>
<li>多媒体</li>
<li>图形学</li>
<li>网络通信、软件工程乃至体系结构、芯片设计</li>
<li>计算机视觉、自然语言处理</li>
<li>交叉学科：生物信息学</li>
</ol>
<h3 id="B-机器学习与数据挖掘的关系"><a href="#B-机器学习与数据挖掘的关系" class="headerlink" title="B 机器学习与数据挖掘的关系"></a>B 机器学习与数据挖掘的关系</h3><p>数据挖掘在二十世纪九十年代形成，受到很多学科领域（比如数据框、机器学习、统计学）的影响。（读者注：R语言诞生于1995开源的S语言），<strong>数据挖掘是从海量数据中发掘知识，这就必然涉及对海量数据的管理和分析。大体来说，数据框领域的研究为数据挖掘提供数据管理技术，而机器学习和统计学的研究为数据挖掘提供数据分析技术。由于统计学界的研究成果通常需要经由机器学习研究来形成有效的学习算法，之后再进入数据挖掘领域，从整个意义上来说，统计学主要是通过机器学习对数据挖掘发挥影响，而机器学习领域和数据库领域则是数据挖掘的两大支撑。</strong></p>
<blockquote>
<p>2004年3月美国DARPA就组织了自动驾驶车比赛。2011年6月，美国内达华州通过法案认可自动驾驶车。</p>
</blockquote>
<h3 id="C-机器学习的不为人知的优点"><a href="#C-机器学习的不为人知的优点" class="headerlink" title="C 机器学习的不为人知的优点"></a>C 机器学习的不为人知的优点</h3><p>机器学习备受瞩目当然是由于它已成为智能数据分析技术的创新源泉，但机器学习研究还有另一个不可忽略的意义，即通过建立一些关于学习的计算模型来促进我们理解 <strong>人类如何学习</strong>。从这个意义上说，机器学习不仅在信息科学中占有重要地位，还具有一定的自然科学探索色彩。</p>
<h2 id="1-8-推荐读物和课后习题"><a href="#1-8-推荐读物和课后习题" class="headerlink" title="1.8 推荐读物和课后习题"></a>1.8 推荐读物和课后习题</h2><p><strong>1.1 表1.1 中若只包含编号1 和 4 的两个样例，试给出相应的版本空间</strong></p>

      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://afrunk.github.io">Afrunk</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://afrunk.github.io/2019/11/26/机器学习-一/">http://afrunk.github.io/2019/11/26/机器学习-一/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/Machine-Learning/">Machine Learning</a>
            <a href="/tags/统计学习方法与西瓜书/">统计学习方法与西瓜书</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2019/11/28/机器学习-二/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">机器学习<二>：模型评估与选择</二></span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2019/11/24/七月 Kaggle Notes 一：机器学习解决方法问题综述课/">
        <span class="next-text nav-default">七月 Kaggle Notes</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:afrunk7@gmail.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/afrunk" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Afrunk</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
