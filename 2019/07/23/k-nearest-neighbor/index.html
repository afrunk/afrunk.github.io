<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="k-nearest-neighbor"><meta name="keywords" content="Mearchine Learning, Hexo"><link rel="alternate" href="/default" title="Hexo"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="http://yoursite.com/2019/07/23/k-nearest-neighbor/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true,"latex":false};
</script>

    <title>k-nearest-neighbor - Hexo</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Hexo</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Hexo</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">k-nearest-neighbor
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-23
        </span></div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、KNN概述"><span class="toc-text">一、KNN概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-工作原理"><span class="toc-text">1.1 工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-三要素"><span class="toc-text">1.2 三要素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-在什么时候选择KNN算法"><span class="toc-text">1.3 在什么时候选择KNN算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、实践案例（主要重点是可视化）"><span class="toc-text">二、实践案例（主要重点是可视化）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-实例一-：电影分类"><span class="toc-text">2.1 实例一 ：电影分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-实例二：优化约会匹配效果"><span class="toc-text">2.2 实例二：优化约会匹配效果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-项目概论"><span class="toc-text">1-项目概论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-开发流程"><span class="toc-text">2-开发流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-收集数据：提供文本"><span class="toc-text">3-收集数据：提供文本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-准备数据：使用python解析文本"><span class="toc-text">4-准备数据：使用python解析文本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-分析数据：使用Matplotlib画二维散点图"><span class="toc-text">5-分析数据：使用Matplotlib画二维散点图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-归一化数值"><span class="toc-text">6-归一化数值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-训练算法"><span class="toc-text">7-训练算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-测试分类错误所占百分比"><span class="toc-text">8-测试分类错误所占百分比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-实践算法：调用算法接口进行预测"><span class="toc-text">9-实践算法：调用算法接口进行预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-完整代码"><span class="toc-text">10-完整代码</span></a></li></ol></li></ol></li></ol>
    </div>
  </div><div class="post-content"><h2 id="一、KNN概述"><a href="#一、KNN概述" class="headerlink" title="一、KNN概述"></a>一、KNN概述</h2><p>简单的说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。</p>
<ol>
<li>优点：精度高、对异常值不敏感、无数据输入假定</li>
<li>缺点：计算复杂度高、空间复杂度高</li>
<li>适用数据范围：数值型和标称型</li>
</ol>
<a id="more"></a>
<h3 id="1-1-工作原理"><a href="#1-1-工作原理" class="headerlink" title="1.1 工作原理"></a>1.1 工作原理</h3><p>KNN可以说是最简单的分类算法之一，同时，它也是最常见的分类算法之一，注意KNN算法是有监督学习的分类算法，它看起来和另外一个机器学习算法Kmeans有点像（Kmeans是无监督学习算法）。</p>
<p>其工作原理是使用一个样本数据集合，也称为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中的数据对应的特征进行比较，然后算法提取样本集中特征最相似（最近邻）的分类标签。一般来说，我们只选择样本集中前k个最相似的数据，这就是KNN中K的出处，最后使用Majority-Voting（多数表决）选择k个最相似数据中次数出现最多的分类，作为新数据的分类。</p>
<h3 id="1-2-三要素"><a href="#1-2-三要素" class="headerlink" title="1.2 三要素"></a>1.2 三要素</h3><ol>
<li>K的取值：可以使用Cross Validation(交叉验证)来选取合适的值<br><br> 我们该如何选择合适的k值呢？通过将样本数据按照一定比例，拆分出训练用的数据和验证用的数据，比如6：4拆出训练数据和验证数据，从选取一个较小的k值开始，不断增加k的值，然后计算验证集合的方差，最终找到一个比较合适的k值。<br><br> <img src="knn-2.png" alt="k值方差验证计算"></li>
<li>距离度量 Metric / Distance Measure:距离度量一般都使用 Euclidean distance（欧氏距离）<br><br> 二维空间两个点的欧式距离公式如下<br><br> <img src="knn-0.jpg" alt="欧式距离"></li>
<li>分类决策 Deision rule：分类决策即Majority-Voting ，选取票数最多的标签，在回归中通常为k个最邻近点的标签的平均值</li>
</ol>
<h3 id="1-3-在什么时候选择KNN算法"><a href="#1-3-在什么时候选择KNN算法" class="headerlink" title="1.3 在什么时候选择KNN算法"></a>1.3 在什么时候选择KNN算法</h3><p><img src="knn-3.png" alt="机器学习选择图"></p>
<h2 id="二、实践案例（主要重点是可视化）"><a href="#二、实践案例（主要重点是可视化）" class="headerlink" title="二、实践案例（主要重点是可视化）"></a>二、实践案例（主要重点是可视化）</h2><h3 id="2-1-实例一-：电影分类"><a href="#2-1-实例一-：电影分类" class="headerlink" title="2.1 实例一 ：电影分类"></a>2.1 实例一 ：电影分类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">电影名称					打斗镜头	接吻镜头	 电影类型</span><br><span class="line">Californla Man				3		104			爱情片</span><br><span class="line">He`s Not Really into Dudes	2		100			爱情片</span><br><span class="line">Beautiful Woman				1		81			爱情片</span><br><span class="line">Kevin Longblade				101		10			动作片</span><br><span class="line">Robo Slayer 3000			99		5			动作片</span><br><span class="line">Ampedll 					98		2			动作片</span><br><span class="line">？							18		90			未知</span><br></pre></td></tr></table></figure>

<p>首先我们通过 Python 的第三方库进行数据可视化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 已知分类的数据</span></span><br><span class="line">x1=np.array([<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">y1=np.array([<span class="number">104</span>,<span class="number">100</span>,<span class="number">81</span>])</span><br><span class="line">x2=np.array([<span class="number">101</span>,<span class="number">99</span>,<span class="number">98</span>])</span><br><span class="line">y2=np.array([<span class="number">10</span>,<span class="number">5</span>,<span class="number">2</span>])</span><br><span class="line">scatter1 = plt.scatter(x1,y1,c=<span class="string">'r'</span>)</span><br><span class="line">scatter2 = plt.scatter(x2,y2,c=<span class="string">'b'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求未知数据</span></span><br><span class="line">x = np.array([<span class="number">18</span>])</span><br><span class="line">y = np.array([<span class="number">90</span>])</span><br><span class="line">scatter3 = plt.scatter(x,y,c=<span class="string">'k'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图例</span></span><br><span class="line">plt.legend(handles=[scatter1,scatter2,scatter3],labels=[<span class="string">'labelA'</span>,<span class="string">'labelB'</span>,<span class="string">'X'</span>],loc = <span class="string">'best'</span> )</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="knn-1.png" alt="可视化效果"></p>
<p>KNN近邻算法最核心的部分就是欧式距离的计算，通过计算得到距离最近的k个数的标签，统计出现次数最多的标签，将其赋值给新数据。下面这段代码就是KNN算法最基本的实例。通过传入数据来预测电影的标签是什么！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 电影分类</span></span><br><span class="line"><span class="comment"># 欧式距离求解返回前k个标签 然后汇总出现次数最多的标签</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 求inX与数据集中各个样本的欧氏距离</span></span><br><span class="line">    diffMat = tile(inX, (dataSetSize,<span class="number">1</span>)) - dataSet   <span class="comment"># numpy中的tile函数将inX复制为重复的dataSize个行和重复的1列，功能相当于MATLAB中的repmat</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)  <span class="comment"># 按照x轴相加</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span></span><br><span class="line">    <span class="comment"># print(distances)</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()   <span class="comment"># 从小到大排序后，返回索引</span></span><br><span class="line">    <span class="comment"># 这个返回索引是关键  只有理解了这个返回索引才能理解k-nn算法</span></span><br><span class="line">    <span class="comment"># print(sortedDistIndicies)</span></span><br><span class="line">    <span class="comment"># 字典，key存储第i小的标签值，value为标签的次数</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]  <span class="comment"># 取第i个小的标签值</span></span><br><span class="line">        <span class="comment"># print(sortedDistIndicies[i])</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span>  <span class="comment"># 根据标签统计标签次数，如果没找到返回0。统计前k个候选者中标签出现的次数</span></span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>) <span class="comment"># operator.itemgetter(1) 按照第2个元素，即标签出现的次数对classCount从大到小排序</span></span><br><span class="line">    <span class="comment"># print(sortedClassCount)  # 测试结果 [('B', 2), ('A', 1)]</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># 返回最终的类别，即标签值key</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 传输数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    group = array([[<span class="number">3</span>,<span class="number">104</span>],[<span class="number">2</span>,<span class="number">100</span>],[<span class="number">1</span>,<span class="number">81</span>],[<span class="number">101</span>,<span class="number">10</span>],[<span class="number">99</span>,<span class="number">5</span>],[<span class="number">98</span>,<span class="number">2</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>,<span class="string">'A'</span>,<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'B'</span>,<span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试代码</span></span><br><span class="line">group, labels = createDataSet()</span><br><span class="line">ans = classify0([<span class="number">18</span>,<span class="number">90</span>], group, labels, <span class="number">3</span>)</span><br><span class="line">print(ans)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A</span><br></pre></td></tr></table></figure>

<h3 id="2-2-实例二：优化约会匹配效果"><a href="#2-2-实例二：优化约会匹配效果" class="headerlink" title="2.2 实例二：优化约会匹配效果"></a>2.2 实例二：优化约会匹配效果</h3><h4 id="1-项目概论"><a href="#1-项目概论" class="headerlink" title="1-项目概论"></a>1-项目概论</h4><p>海伦使用约会网站寻求约会对象，经过一段实践之后，她发现曾交往过三类人：</p>
<ul>
<li>不喜欢的人</li>
<li>魅力一般的人</li>
<li>极具魅力的人</li>
</ul>
<p>她希望：</p>
<ol>
<li>工作日与魅力一般的人约会</li>
<li>周末与极具魅力的人约会</li>
<li>不喜欢的人则直接排除掉</li>
</ol>
<p>现在她收集到了一些约会网站未曾记录的数据信息，这更有助于匹配对象的归类。</p>
<h4 id="2-开发流程"><a href="#2-开发流程" class="headerlink" title="2-开发流程"></a>2-开发流程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. 收集数据：提供文本文件</span><br><span class="line">2. 准本数据：使用Python解析文本文件</span><br><span class="line">3. 分析数据：使用Matplotlib 画二维散点图</span><br><span class="line">4. 训练算法：此步骤不适用与KNN算法，但是也很重要</span><br><span class="line">5. 测试数据：使用海伦提供的部分数据作为测试样本</span><br><span class="line">6. 使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型</span><br></pre></td></tr></table></figure>

<p>测试样本与非测试样本的区别在于：<br>测试样本是以及完成分类的数据，如果测试分类与实际类不同，则标记为一个错误</p>
<h4 id="3-收集数据：提供文本"><a href="#3-收集数据：提供文本" class="headerlink" title="3-收集数据：提供文本"></a>3-收集数据：提供文本</h4><p>海伦把这些约会对象的数据存放在文本文件 <a href="https://github.com/apachecn/AiLearning/blob/master/data/2.KNN/datingTestSet2.txt" target="_blank" rel="noopener">datingTestSet2.txt</a> 中，总共有1000行，海伦约会的对象主要包含以下3种特征：</p>
<ul>
<li>每年获得的飞行常客里程数</li>
<li>玩视频游戏所耗费时间百分比</li>
<li>每周消费的冰激凌公升数</li>
</ul>
<p>文本文件数据格式如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">40920	8.326976	0.953952	3</span><br><span class="line">14488	7.153469	1.673904	2</span><br><span class="line">26052	1.441871	0.805124	1</span><br><span class="line">75136	13.147394	0.428964	1</span><br><span class="line">38344	1.669788	0.134296	1</span><br></pre></td></tr></table></figure>

<h4 id="4-准备数据：使用python解析文本"><a href="#4-准备数据：使用python解析文本" class="headerlink" title="4-准备数据：使用python解析文本"></a>4-准备数据：使用python解析文本</h4><p>将文本记录转换为 NUmPy的解析程序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc：</span></span><br><span class="line"><span class="string">        导入训练数据</span></span><br><span class="line"><span class="string">    Parameters：</span></span><br><span class="line"><span class="string">        filename：数据文件路径</span></span><br><span class="line"><span class="string">    return：</span></span><br><span class="line"><span class="string">        数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    <span class="comment"># 获得文件中的数据行的行数</span></span><br><span class="line">    numberOfLines = len(fr.readlines())</span><br><span class="line">    <span class="comment"># 生成对应的空矩阵</span></span><br><span class="line">    <span class="comment"># 例如：zeros(2,3)就是生成一个 2*3 的矩阵，各个位置上全是0</span></span><br><span class="line">    returnMat = zeros((numberOfLines , <span class="number">3</span>)) <span class="comment"># prepare matrix to return</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    index =<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># str.strip([chars]) -- 返回已移除字符串头尾指定字符所生成的新字符串</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 以 \t  切割字符串</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 每列的属性数据</span></span><br><span class="line">        returnMat[index , : ] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 每列的类别数据，就是 label 标签数据</span></span><br><span class="line">        classLabelVector.append(int(listFromLine[<span class="number">-1</span>]))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 返回数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line">    print(returnMat,classLabelVector)</span><br><span class="line">    <span class="keyword">return</span> returnMat,classLabelVector</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    file2matrix(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[[<span class="number">4.0920000e+04</span> <span class="number">8.3269760e+00</span> <span class="number">9.5395200e-01</span>]</span><br><span class="line"> [<span class="number">1.4488000e+04</span> <span class="number">7.1534690e+00</span> <span class="number">1.6739040e+00</span>]</span><br><span class="line"> [<span class="number">2.6052000e+04</span> <span class="number">1.4418710e+00</span> <span class="number">8.0512400e-01</span>]</span><br><span class="line"> ...</span><br><span class="line"> [<span class="number">2.6575000e+04</span> <span class="number">1.0650102e+01</span> <span class="number">8.6662700e-01</span>]</span><br><span class="line"> [<span class="number">4.8111000e+04</span> <span class="number">9.1345280e+00</span> <span class="number">7.2804500e-01</span>]</span><br><span class="line"> [<span class="number">4.3757000e+04</span> <span class="number">7.8826010e+00</span> <span class="number">1.3324460e+00</span>]] [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<h4 id="5-分析数据：使用Matplotlib画二维散点图"><a href="#5-分析数据：使用Matplotlib画二维散点图" class="headerlink" title="5-分析数据：使用Matplotlib画二维散点图"></a>5-分析数据：使用Matplotlib画二维散点图</h4><p>下面的代码里面有三分可视化的结果，但是我们可以在 Notebook中很明显的看到每年获取的飞行里程数和玩视频游戏所消耗的时间百分比所构成的坐标图非常的清晰的分成三个部分，这就为我们后续的计算距离分类奠定基础。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc：</span></span><br><span class="line"><span class="string">        导入训练数据</span></span><br><span class="line"><span class="string">    Parameters：</span></span><br><span class="line"><span class="string">        filename：数据文件路径</span></span><br><span class="line"><span class="string">    return：</span></span><br><span class="line"><span class="string">        数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    <span class="comment"># 获得文件中的数据行的行数</span></span><br><span class="line">    numberOfLines = len(fr.readlines())</span><br><span class="line">    <span class="comment"># 生成对应的空矩阵</span></span><br><span class="line">    <span class="comment"># 例如：zeros(2,3)就是生成一个 2*3 的矩阵，各个位置上全是0</span></span><br><span class="line">    returnMat = zeros((numberOfLines , <span class="number">3</span>)) <span class="comment"># prepare matrix to return</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    index =<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># str.strip([chars]) -- 返回已移除字符串头尾指定字符所生成的新字符串</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 以 \t  切割字符串</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 每列的属性数据</span></span><br><span class="line">        returnMat[index , : ] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 每列的类别数据，就是 label 标签数据</span></span><br><span class="line">        classLabelVector.append(int(listFromLine[<span class="number">-1</span>]))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 返回数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line">    <span class="comment"># print(returnMat,classLabelVector)</span></span><br><span class="line">    <span class="keyword">return</span> returnMat,classLabelVector</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为 matplotlib 中不可显示中文，所以使用本机自带的字体进行替换</span></span><br><span class="line"><span class="comment"># 参考链接：https://www.cnblogs.com/pengsky2016/p/8126623.html</span></span><br><span class="line"><span class="comment"># 该链接是本书的该可视化部分的详细讲解 非常不错</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties </span><br><span class="line">zhfont = FontProperties(fname=<span class="string">'C:\\Windows\\Fonts\\msyh.ttc'</span>,size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    datingDataMat,datingLabels  =  file2matrix(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     print(datingDataMat)</span></span><br><span class="line"><span class="comment">#     print(datingLabels)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> matplotlib</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line">    </span><br><span class="line">    datingLabels = np.array(datingLabels)</span><br><span class="line"><span class="comment">#     每年获取的飞行里程数-玩视频游戏所消耗的事件百分比</span></span><br><span class="line"><span class="comment">#     datingDataMat[idx_1,0] 中的参数 0 和 1 以及 2 就是我们所选择的横坐标和纵坐标的选取值</span></span><br><span class="line"><span class="comment">#     我们可以根据这三个值的变动来变动我们的坐标轴的选取方法</span></span><br><span class="line">    idx_1 = np.where(datingLabels==<span class="number">1</span>)</span><br><span class="line">    p1 = ax.scatter(datingDataMat[idx_1,<span class="number">0</span>],datingDataMat[idx_1,<span class="number">1</span>],marker = <span class="string">'*'</span>,color = <span class="string">'r'</span>,label=<span class="string">'1'</span>,s=<span class="number">10</span>)</span><br><span class="line">    idx_2 = np.where(datingLabels==<span class="number">2</span>)</span><br><span class="line">    p2 = ax.scatter(datingDataMat[idx_2,<span class="number">0</span>],datingDataMat[idx_2,<span class="number">1</span>],marker = <span class="string">'o'</span>,color =<span class="string">'g'</span>,label=<span class="string">'2'</span>,s=<span class="number">20</span>)</span><br><span class="line">    idx_3 = np.where(datingLabels==<span class="number">3</span>)</span><br><span class="line">    p3 = ax.scatter(datingDataMat[idx_3,<span class="number">0</span>],datingDataMat[idx_3,<span class="number">1</span>],marker = <span class="string">'+'</span>,color =<span class="string">'b'</span>,label=<span class="string">'3'</span>,s=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">u'每年获取的飞行里程数'</span>, fontproperties=zhfont)</span><br><span class="line">    plt.ylabel(<span class="string">u'玩视频游戏所消耗的事件百分比'</span>, fontproperties=zhfont)</span><br><span class="line">    ax.legend((p1, p2, p3), (<span class="string">u'不喜欢'</span>, <span class="string">u'魅力一般'</span>, <span class="string">u'极具魅力'</span>), loc=<span class="number">2</span>, prop=zhfont)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment">#     玩视频游戏所消耗的事件百分比-每周消耗的冰激凌公升数</span></span><br><span class="line"><span class="comment">#     datingLabels = np.array(datingLabels)</span></span><br><span class="line"><span class="comment">#     idx_1 = np.where(datingLabels==1)</span></span><br><span class="line"><span class="comment">#     p1 = ax.scatter(datingDataMat[idx_1,1],datingDataMat[idx_1,2],marker = '*',color = 'r',label='1',s=10)</span></span><br><span class="line"><span class="comment">#     idx_2 = np.where(datingLabels==2)</span></span><br><span class="line"><span class="comment">#     p2 = ax.scatter(datingDataMat[idx_2,1],datingDataMat[idx_2,2],marker = 'o',color ='g',label='2',s=20)</span></span><br><span class="line"><span class="comment">#     idx_3 = np.where(datingLabels==3)</span></span><br><span class="line"><span class="comment">#     p3 = ax.scatter(datingDataMat[idx_3,1],datingDataMat[idx_3,2],marker = '+',color ='b',label='3',s=30)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#     plt.xlabel(u'玩视频游戏所消耗的事件百分比', fontproperties=zhfont)</span></span><br><span class="line"><span class="comment">#     plt.ylabel(u'', fontproperties=zhfont)</span></span><br><span class="line"><span class="comment">#     ax.legend((p1, p2, p3), (u'不喜欢', u'魅力一般', u'极具魅力'), loc=2, prop=zhfont)</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">#     飞行常客里程数 - 每周消耗的冰激凌公升数</span></span><br><span class="line"><span class="comment">#     datingLabels = np.array(datingLabels)</span></span><br><span class="line"><span class="comment">#     idx_1 = np.where(datingLabels==1)</span></span><br><span class="line"><span class="comment">#     p1 = ax.scatter(datingDataMat[idx_1,0],datingDataMat[idx_1,2],marker = '*',color = 'r',label='1',s=10)</span></span><br><span class="line"><span class="comment">#     idx_2 = np.where(datingLabels==2)</span></span><br><span class="line"><span class="comment">#     p2 = ax.scatter(datingDataMat[idx_2,0],datingDataMat[idx_2,2],marker = 'o',color ='g',label='2',s=20)</span></span><br><span class="line"><span class="comment">#     idx_3 = np.where(datingLabels==3)</span></span><br><span class="line"><span class="comment">#     p3 = ax.scatter(datingDataMat[idx_3,0],datingDataMat[idx_3,2],marker = '+',color ='b',label='3',s=30)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     plt.xlabel(u'每年获取的飞行里程数', fontproperties=zhfont)</span></span><br><span class="line"><span class="comment">#     plt.ylabel(u'玩视频游戏所消耗的事件百分比', fontproperties=zhfont)</span></span><br><span class="line"><span class="comment">#     ax.legend((p1, p2, p3), (u'不喜欢', u'魅力一般', u'极具魅力'), loc=2, prop=zhfont)</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br></pre></td></tr></table></figure>

<p><img src="knn-5.png" alt="可视化图"></p>
<h4 id="6-归一化数值"><a href="#6-归一化数值" class="headerlink" title="6-归一化数值"></a>6-归一化数值</h4><p>归一化数据是一个让权重变为统一的过程，比如你要买进10吨铁矿，用的人民币和美元肯定不同，那么这10吨铁矿的价值到底是多少，就需要一个统一的标准来衡量，全世界那么多国家，都要用自己国家的货币去买，到底该付多少就很迷茫。这时，规定用美元统一结算，各国按照本国货币对比美元的汇率，再加上10吨铁矿的美元价值，就可以算出自己应付多少本国货币。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">序号	 玩视频游戏所耗时间百分比	每年获得的飞行常客里程数	每周消耗的冰激凌公升数	样本分类</span><br><span class="line">1		0.8					400						0.5						1</span><br><span class="line">2		12					134000					0.9						3</span><br><span class="line">3		0					20000					1.1						2</span><br><span class="line">4		67					32000					0.1						2</span><br></pre></td></tr></table></figure>

<p>表2-2给出了提取的四组数据，如果想要计算样本3和样本4之间的距离，可以使用下面的方法：<br>√((0−67)^2+(20 000 −32 000)^2+(1.1 −0.1)^2 )</p>
<p>我们很容易发现，上面方程中数字差值最大的数学对计算结果的影响最大，也就是说，每年获取的飞行常客里程数对于计算结果的影响远远大于表2-</p>
<p>在处理这种不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为0到1或-1到1之间。下面的公式可以将任意取值范围的特征值转换为0到1区间内的值：<br><br><code>newValue = (oldValue - min ) / (max - min)</code><br><br>其中 min 和 max 分别是数据集中的最小特征值和最大特征值。虽然改变数值取值范围增加了分类器的复杂度，但为了得到准确结果，我们必须这样子做。我们需要在文件中增加一个新的函数 autoNorm()，该函数可以自动将数字特征值转换为0到1的区间。<br>2中其他两个特征——玩视频游戏和每周消费冰激凌公升数——的影响。而产生这种现象的唯一远远，仅仅是因为飞行常客里程数远大于其他特征值。但海伦认为这三种特征是同等重要的，因此作为三个等权重的特征之一，飞行常客里程数并不应该如此严重的影响到计算结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc：</span></span><br><span class="line"><span class="string">        导入训练数据</span></span><br><span class="line"><span class="string">    Parameters：</span></span><br><span class="line"><span class="string">        filename：数据文件路径</span></span><br><span class="line"><span class="string">    return：</span></span><br><span class="line"><span class="string">        数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    <span class="comment"># 获得文件中的数据行的行数</span></span><br><span class="line">    numberOfLines = len(fr.readlines())</span><br><span class="line">    <span class="comment"># 生成对应的空矩阵</span></span><br><span class="line">    <span class="comment"># 例如：zeros(2,3)就是生成一个 2*3 的矩阵，各个位置上全是0</span></span><br><span class="line">    returnMat = zeros((numberOfLines , <span class="number">3</span>)) <span class="comment"># prepare matrix to return</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    index =<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># str.strip([chars]) -- 返回已移除字符串头尾指定字符所生成的新字符串</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 以 \t  切割字符串</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 每列的属性数据</span></span><br><span class="line">        returnMat[index , : ] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 每列的类别数据，就是 label 标签数据</span></span><br><span class="line">        classLabelVector.append(int(listFromLine[<span class="number">-1</span>]))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 返回数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line">    <span class="comment"># print(returnMat,classLabelVector)</span></span><br><span class="line">    <span class="keyword">return</span> returnMat,classLabelVector</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc:</span></span><br><span class="line"><span class="string">        归一化特征值，消除特征之间量级不同导致的影响</span></span><br><span class="line"><span class="string">    parameter:</span></span><br><span class="line"><span class="string">        dataset:数据集</span></span><br><span class="line"><span class="string">    return :</span></span><br><span class="line"><span class="string">        归一化后的数据集 normDataSet , ranges 和 minVals 即最小值与范围，并没有归一化公式</span></span><br><span class="line"><span class="string">    归一化公式：</span></span><br><span class="line"><span class="string">        Y=(X-Xmin)/(Xmax - Xmin)</span></span><br><span class="line"><span class="string">        其中的 min 和 max 分别是数据集中的最小特征值和最大特征值，该函数可以自动将数字特征值转化为0到1的区间</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 计算每种属性的最大值、最小值、范围</span></span><br><span class="line">    minVals = dataset.min(<span class="number">0</span>)</span><br><span class="line">    maxVals = dataset.max(<span class="number">0</span>)</span><br><span class="line">    ranges = maxVals - minVals</span><br><span class="line">    <span class="comment"># 极差</span></span><br><span class="line">    normDataSet = zeros(shape(dataset))</span><br><span class="line">    m = dataset.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#生成与最小值之差组成的矩阵</span></span><br><span class="line">    <span class="comment"># 因为特征值矩阵有1000 * 3 个值，而 minVals 和 range 的值都为1x3，</span></span><br><span class="line">    <span class="comment"># 为了解决这个问题，我们使用Numpy库中的tile()函数将变量内容复制成输入矩阵同样大小的矩阵，</span></span><br><span class="line">    <span class="comment"># 注意这是具体特征值相除，而不是矩阵除法，否则还需要使用函数linalg.solve(matA,matB)</span></span><br><span class="line">    normDataSet = dataset - tile(minVals, (m,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将最小值之差除以范围组成矩阵</span></span><br><span class="line">    normDataSet = normDataSet / tile(ranges, (m,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> normDataSet,range,minVals</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    datingDataMat,datingLabels  =  file2matrix(<span class="number">1</span>)</span><br><span class="line">    normMat,ranges,minVals = autoNorm(datingDataMat)</span><br><span class="line">    print(normMat)</span><br><span class="line">    print(range)</span><br><span class="line">    print(minVals)</span><br></pre></td></tr></table></figure>

<h4 id="7-训练算法"><a href="#7-训练算法" class="headerlink" title="7-训练算法"></a>7-训练算法</h4><p>这个是核心内容，即计算各个标记点之间的距离并返回k个标记点内出现次数最多的标签。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对于每一个在数据集中的数据点：</span><br><span class="line">	计算目标的数据点（需要分类的数据点） 与该数据点的距离</span><br><span class="line">	将距离排序：从小到大</span><br><span class="line">	选取k个最短距离</span><br><span class="line">	选取这k个最多的分类类别</span><br><span class="line">	返回该类别来作为目标数据点的预测值</span><br></pre></td></tr></table></figure>

<p>整个训练算法和之前的电影分类的算法是一致的，该算法进化的部分即对数据进行了归一化处理，导致我们传入进去的数据也需要进行归一化处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练算法</span></span><br><span class="line"><span class="comment"># 详解 k-nn训练算法 ：https://www.cnblogs.com/BaiYiShaoNian/p/4567446.html</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX,dataSet,labels,k)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param inX:  用于分类的输入向量</span></span><br><span class="line"><span class="string">    :param dataSet: 训练样本集合</span></span><br><span class="line"><span class="string">    :param labels: 标签向量</span></span><br><span class="line"><span class="string">    :param k:  K-NN中的k</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># shape 是array的属性 ，描述一个多维数组的维度</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 距离度量 度量公式为欧式距离</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    tile(inX,(dataSetSize,1)) : 把 inX 二维数组化，dataSetSize 表示生成数组后的行数</span></span><br><span class="line"><span class="string">    1 表示列的倍数，整个这一行代表表示前一个二维数组矩阵的每一个元素减去后一个数组对应的元素值</span></span><br><span class="line"><span class="string">    这样子就实现了矩阵之间的减法，简单方便</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    diffMat = tile(inX,(dataSetSize,<span class="number">1</span>)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat ** <span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># axis=1 表示矩阵中行之间数的求和 axis=0表示列之间数的求和</span></span><br><span class="line">    distances = sqDistances ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将距离排序：从小到大</span></span><br><span class="line">    <span class="comment"># 关键是传回的是位置索引 而这个索引就可以得到在标签中所对应位置的标签</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    <span class="comment">#选取前k个最短距离，选取这k个中最多的分类类别</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line"><span class="comment">#     print(labels)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        <span class="comment"># 这一行是python语法 看不懂基础问题</span></span><br><span class="line">        <span class="comment"># get()该方法是访问字典项的方法，即访问下标为 voteIlabel的项，如果没有这一项，那么初始值为0</span></span><br><span class="line">        <span class="comment"># 然后把这一项的值加1</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">import</span> operator</span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(<span class="number">1</span>),reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<h4 id="8-测试分类错误所占百分比"><a href="#8-测试分类错误所占百分比" class="headerlink" title="8-测试分类错误所占百分比"></a>8-测试分类错误所占百分比</h4><p>该函数的代码是统计该KNN算法的实现效果，抽取一部分的数据作为数据集，进行测试然后统计测试错误的百分比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试分类错误，错误分辨个数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></span><br><span class="line">    hoRatio = <span class="number">0.08</span>      <span class="comment"># 随机挖去 10% 的数据作为测试集</span></span><br><span class="line">    datingDataMat,datingLabels = file2matrix(<span class="string">'datingTestSet2.txt'</span>)       <span class="comment"># 加载数据文件</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    m = normMat.shape[<span class="number">0</span>]</span><br><span class="line">    numTestVecs = int(m*hoRatio)  <span class="comment"># 随机挖去的行数</span></span><br><span class="line">    errorCount = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</span><br><span class="line">    	<span class="comment"># 前numTestVecs条作为测试集（一个一个测试），后面的数据作为训练样本，训练样本的标签，3个近邻</span></span><br><span class="line">        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:], datingLabels[numTestVecs:m], <span class="number">3</span>)</span><br><span class="line">        print(<span class="string">"the classifier came back with: %d, the real answer is: %d"</span> % (classifierResult, datingLabels[i]))</span><br><span class="line">        <span class="keyword">if</span> (classifierResult != datingLabels[i]): errorCount += <span class="number">1.0</span></span><br><span class="line">    print(<span class="string">"The number of errr is: %d"</span> % int(errorCount))</span><br><span class="line">    print(<span class="string">"The total error rate is: %f"</span> % (errorCount / float(numTestVecs)))</span><br><span class="line">&gt;&gt;&gt;The number of errr <span class="keyword">is</span>: <span class="number">2</span></span><br><span class="line">&gt;&gt;&gt;The total error rate <span class="keyword">is</span>: <span class="number">0.025000</span></span><br></pre></td></tr></table></figure>

<h4 id="9-实践算法：调用算法接口进行预测"><a href="#9-实践算法：调用算法接口进行预测" class="headerlink" title="9-实践算法：调用算法接口进行预测"></a>9-实践算法：调用算法接口进行预测</h4><p>直接在主函数中使用该函数调用数据预处理函数传入数据、调用归一化数据处理函数归一化数据、调用训练算法传入数据进行预测，最后输出算法判断后的结论。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实践算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validateTest</span><span class="params">()</span>:</span></span><br><span class="line">    resultList = [<span class="string">'not at all'</span>, <span class="string">'in small doses'</span>, <span class="string">'in large doses'</span>]</span><br><span class="line">    percentTats = float(input(<span class="string">"percentage of time spent playing video games ?"</span>))</span><br><span class="line">    ffMiles = float(input(<span class="string">"frequent filer miles earned per year?"</span>))</span><br><span class="line">    iceCream = float(input(<span class="string">"liters of ice cream consumed per year?"</span>))</span><br><span class="line">    datingDataMat, datingLabels = file2matrix(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    inArr = array([ffMiles, percentTats, iceCream])</span><br><span class="line"><span class="comment">#     print(str(inArr),str(minVals),str(ranges),normMat,datingLabels)</span></span><br><span class="line">    <span class="comment"># 为什么传入的值需要进行 如下操作呢 (inArry - minVals)/range</span></span><br><span class="line">    <span class="comment"># 因为我们之前传入的值都是进行过归一化的</span></span><br><span class="line">    <span class="comment"># 但是如果直接传入值会过大 所以我们在前面的归一化操作中将两个参数传过来就是为了这里使用</span></span><br><span class="line">    <span class="comment"># 但是这里传入的测试参数也是一个1x3的举证 所有 minVals 和 ranges 不需要进行 tile化</span></span><br><span class="line">    classifierResult = classify0((inArr - minVals) / ranges, normMat, datingLabels, <span class="number">3</span>)</span><br><span class="line">    print(<span class="string">"You will probably like this person: "</span>, resultList[classifierResult - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 实践算法</span></span><br><span class="line">    validateTest()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;percentage of time spent playing video games ?10</span><br><span class="line">&gt;&gt;&gt;frequent filer miles earned per year?10000</span><br><span class="line">&gt;&gt;&gt;liters of ice cream consumed per year?0.5</span><br><span class="line">&gt;&gt;&gt;You will probably like this person:  <span class="keyword">in</span> small doses</span><br></pre></td></tr></table></figure>

<h4 id="10-完整代码"><a href="#10-完整代码" class="headerlink" title="10-完整代码"></a>10-完整代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc：</span></span><br><span class="line"><span class="string">        导入训练数据</span></span><br><span class="line"><span class="string">    Parameters：</span></span><br><span class="line"><span class="string">        filename：数据文件路径</span></span><br><span class="line"><span class="string">    return：</span></span><br><span class="line"><span class="string">        数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    <span class="comment"># 获得文件中的数据行的行数</span></span><br><span class="line">    numberOfLines = len(fr.readlines())</span><br><span class="line">    <span class="comment"># 生成对应的空矩阵</span></span><br><span class="line">    <span class="comment"># 例如：zeros(2,3)就是生成一个 2*3 的矩阵，各个位置上全是0</span></span><br><span class="line">    returnMat = zeros((numberOfLines, <span class="number">3</span>))  <span class="comment"># prepare matrix to return</span></span><br><span class="line">    classLabelVector = []</span><br><span class="line">    fr = open(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        <span class="comment"># str.strip([chars]) -- 返回已移除字符串头尾指定字符所生成的新字符串</span></span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="comment"># 以 \t  切割字符串</span></span><br><span class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment"># 每列的属性数据</span></span><br><span class="line">        returnMat[index, :] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 每列的类别数据，就是 label 标签数据</span></span><br><span class="line">        classLabelVector.append(int(listFromLine[<span class="number">-1</span>]))</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 返回数据矩阵 returnMat 和对应的类别 classLabelVector</span></span><br><span class="line">    <span class="comment"># print(returnMat,classLabelVector)</span></span><br><span class="line">    <span class="keyword">return</span> returnMat, classLabelVector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为 matplotlib 中不可显示中文，所以使用本机自带的字体进行替换</span></span><br><span class="line"><span class="comment"># 参考链接：https://www.cnblogs.com/pengsky2016/p/8126623.html</span></span><br><span class="line"><span class="comment"># 该链接是本书的该可视化部分的详细讲解 非常不错</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line">zhfont = FontProperties(fname=<span class="string">'C:\\Windows\\Fonts\\msyh.ttc'</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化特征值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Desc:</span></span><br><span class="line"><span class="string">        归一化特征值，消除特征之间量级不同导致的影响</span></span><br><span class="line"><span class="string">    parameter:</span></span><br><span class="line"><span class="string">        dataset:数据集</span></span><br><span class="line"><span class="string">    return :</span></span><br><span class="line"><span class="string">        归一化后的数据集 normDataSet , ranges 和 minVals 即最小值与范围，并没有归一化公式</span></span><br><span class="line"><span class="string">    归一化公式：</span></span><br><span class="line"><span class="string">        Y=(X-Xmin)/(Xmax - Xmin)</span></span><br><span class="line"><span class="string">        其中的 min 和 max 分别是数据集中的最小特征值和最大特征值，该函数可以自动将数字特征值转化为0到1的区间</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 计算每种属性的最大值、最小值、范围</span></span><br><span class="line">    minVals = dataset.min(<span class="number">0</span>)</span><br><span class="line">    maxVals = dataset.max(<span class="number">0</span>)</span><br><span class="line">    ranges = maxVals - minVals</span><br><span class="line">    <span class="comment"># 极差</span></span><br><span class="line">    normDataSet = zeros(shape(dataset))</span><br><span class="line">    m = dataset.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#生成与最小值之差组成的矩阵</span></span><br><span class="line">    <span class="comment"># 因为特征值矩阵有1000 * 3 个值，而 minVals 和 range 的值都为1x3，</span></span><br><span class="line">    <span class="comment"># 为了解决这个问题，我们使用Numpy库中的tile()函数将变量内容复制成输入矩阵同样大小的矩阵，</span></span><br><span class="line">    <span class="comment"># 注意这是具体特征值相除，而不是矩阵除法，否则还需要使用函数linalg.solve(matA,matB)</span></span><br><span class="line">    normDataSet = dataset - tile(minVals, (m,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将最小值之差除以范围组成矩阵</span></span><br><span class="line">    normDataSet = normDataSet / tile(ranges, (m,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> normDataSet,ranges,minVals</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练算法</span></span><br><span class="line"><span class="comment"># 详解 k-nn训练算法 ：https://www.cnblogs.com/BaiYiShaoNian/p/4567446.html</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX,dataSet,labels,k)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param inX:  用于分类的输入向量</span></span><br><span class="line"><span class="string">    :param dataSet: 训练样本集合</span></span><br><span class="line"><span class="string">    :param labels: 标签向量</span></span><br><span class="line"><span class="string">    :param k:  K-NN中的k</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># shape 是array的属性 ，描述一个多维数组的维度</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 距离度量 度量公式为欧式距离</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    tile(inX,(dataSetSize,1)) : 把 inX 二维数组化，dataSetSize 表示生成数组后的行数</span></span><br><span class="line"><span class="string">    1 表示列的倍数，整个这一行代表表示前一个二维数组矩阵的每一个元素减去后一个数组对应的元素值</span></span><br><span class="line"><span class="string">    这样子就实现了矩阵之间的减法，简单方便</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    diffMat = tile(inX,(dataSetSize,<span class="number">1</span>)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat ** <span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># axis=1 表示矩阵中行之间数的求和 axis=0表示列之间数的求和</span></span><br><span class="line">    distances = sqDistances ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将距离排序：从小到大</span></span><br><span class="line">    <span class="comment"># 关键是传回的是位置索引 而这个索引就可以得到在标签中所对应位置的标签</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    <span class="comment">#选取前k个最短距离，选取这k个中最多的分类类别</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line"><span class="comment">#     print(labels)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]</span><br><span class="line">        <span class="comment"># 这一行是python语法 看不懂基础问题</span></span><br><span class="line">        <span class="comment"># get()该方法是访问字典项的方法，即访问下标为 voteIlabel的项，如果没有这一项，那么初始值为0</span></span><br><span class="line">        <span class="comment"># 然后把这一项的值加1</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">import</span> operator</span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(<span class="number">1</span>),reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试分类错误，错误分辨个数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></span><br><span class="line">    hoRatio = <span class="number">0.08</span>      <span class="comment"># 随机挖去 10% 的数据作为测试集</span></span><br><span class="line">    datingDataMat,datingLabels = file2matrix(<span class="string">'datingTestSet2.txt'</span>)       <span class="comment"># 加载数据文件</span></span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    m = normMat.shape[<span class="number">0</span>]</span><br><span class="line">    numTestVecs = int(m*hoRatio)  <span class="comment"># 随机挖去的行数</span></span><br><span class="line">    errorCount = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</span><br><span class="line">    	<span class="comment"># 前numTestVecs条作为测试集（一个一个测试），后面的数据作为训练样本，训练样本的标签，3个近邻</span></span><br><span class="line">        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:], datingLabels[numTestVecs:m], <span class="number">3</span>)</span><br><span class="line">        print(<span class="string">"the classifier came back with: %d, the real answer is: %d"</span> % (classifierResult, datingLabels[i]))</span><br><span class="line">        <span class="keyword">if</span> (classifierResult != datingLabels[i]): errorCount += <span class="number">1.0</span></span><br><span class="line">    print(<span class="string">"The number of errr is: %d"</span> % int(errorCount))</span><br><span class="line">    print(<span class="string">"The total error rate is: %f"</span> % (errorCount / float(numTestVecs)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实践算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validateTest</span><span class="params">()</span>:</span></span><br><span class="line">    resultList = [<span class="string">'not at all'</span>, <span class="string">'in small doses'</span>, <span class="string">'in large doses'</span>]</span><br><span class="line">    percentTats = float(input(<span class="string">"percentage of time spent playing video games ?"</span>))</span><br><span class="line">    ffMiles = float(input(<span class="string">"frequent filer miles earned per year?"</span>))</span><br><span class="line">    iceCream = float(input(<span class="string">"liters of ice cream consumed per year?"</span>))</span><br><span class="line">    datingDataMat, datingLabels = file2matrix(<span class="string">'datingTestSet2.txt'</span>)</span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    inArr = array([ffMiles, percentTats, iceCream])</span><br><span class="line"><span class="comment">#     print(str(inArr),str(minVals),str(ranges),normMat,datingLabels)</span></span><br><span class="line">    <span class="comment"># 为什么传入的值需要进行 如下操作呢 (inArry - minVals)/range</span></span><br><span class="line">    <span class="comment"># 因为我们之前传入的值都是进行过归一化的</span></span><br><span class="line">    <span class="comment"># 但是如果直接传入值会过大 所以我们在前面的归一化操作中将两个参数传过来就是为了这里使用</span></span><br><span class="line">    <span class="comment"># 但是这里传入的测试参数也是一个1x3的举证 所有 minVals 和 ranges 不需要进行 tile化</span></span><br><span class="line">    classifierResult = classify0((inArr - minVals) / ranges, normMat, datingLabels, <span class="number">3</span>)</span><br><span class="line">    print(<span class="string">"You will probably like this person: "</span>, resultList[classifierResult - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 实践算法</span></span><br><span class="line">    validateTest()</span><br><span class="line">    <span class="comment"># 测试分类错误：判断程序的可行性</span></span><br><span class="line">    print(<span class="string">"这是输出判断算法优越性的结果："</span>)</span><br><span class="line">    datingClassTest()</span><br></pre></td></tr></table></figure>


      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://yoursite.com">John Doe</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://yoursite.com/2019/07/23/k-nearest-neighbor/">http://yoursite.com/2019/07/23/k-nearest-neighbor/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/Mearchine-Learning/">Mearchine Learning</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2019/07/23/kaggle-movie-reviews/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Kaggle-Senment Analysis on Moview Reviews</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2019/07/23/Hexo-Github-1/">
        <span class="next-text nav-default">Hexo-Github</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/ahonn" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">John Doe</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
