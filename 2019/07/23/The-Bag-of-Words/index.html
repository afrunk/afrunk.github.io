<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="Sklearn-Text character extraction： BoW & TF-IDF"><meta name="keywords" content="Machine Learning, Sklearn, 天道宫"><link rel="alternate" href="/default" title="天道宫"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="http://afrunk.github.io/2019/07/23/The-Bag-of-Words/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css"><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true,"latex":true};
</script>

    <title>Sklearn-Text character extraction： BoW & TF-IDF - 天道宫</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">天道宫</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">Home
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">Archivew
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">天道宫</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            Archivew
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            Tags
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            Categories
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            About
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">Sklearn-Text character extraction： BoW & TF-IDF
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-23
        </span><span class="post-category">
            <a href="/categories/Sklearn-使用文档/">Sklearn 使用文档</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、Sklearn"><span class="toc-text">一、Sklearn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、词袋模型"><span class="toc-text">二、词袋模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-词袋模型在各个领域的使用"><span class="toc-text">2.1 词袋模型在各个领域的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Sklearn-BoW-的使用方法"><span class="toc-text">2.2 Sklearn-BoW 的使用方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、TF-IDF"><span class="toc-text">三、TF-IDF</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Sklearn-TF-IDF-的使用方法"><span class="toc-text">3.1 Sklearn-TF-IDF 的使用方法</span></a></li></ol></li></ol>
    </div>
  </div><div class="post-content"><p>本文的背景是Kaggle题目：Sentiment Analysis on Movie Reviews中使用<code>Sklearn</code>的词袋模型和TF-IDF模型来进行特征工程处理。所以从这两个模型出发来学习下Sklearn这个机器学习著名的工具。</p>
<a id="more"></a>
<h2 id="一、Sklearn"><a href="#一、Sklearn" class="headerlink" title="一、Sklearn"></a>一、Sklearn</h2><p>首先附上 <a href="https://scikit-learn.org/stable/index.html#" target="_blank" rel="noopener">Sklearn</a> 的中文文档：<a href="https://sklearn.apachecn.org/#/" target="_blank" rel="noopener">scikit-learn 0.21.x 中文文档</a>.(这里不推荐使用其他的书，因为已经有了官方文档了，如果硬要看的话有《Sklearn与TensorFlow机器学习实用指南》以及莫烦和其他有关 Sklearn 的视频。)该文档也是ApacheCN 组织翻译的，之前我也看了他们的教程(比如这个学习路线：<a href="https://github.com/apachecn/ai-roadmap/tree/master/v1.0" target="_blank" rel="noopener">ApacheCN 人工智能知识树</a>)，总结的还算不错，视频的话只能说一般，不过不管怎么样说他们还是很优秀的。</p>
<p>首先，给出定义：Scikit-learn 是基于 Python 语言的机器学习工具。</p>
<ol>
<li>简单高效的数据挖掘和数据分析工具</li>
<li>建立在NumPy，SciPy和 Matplotlib 上</li>
</ol>
<p>其次，机器学习中的基本算法都可以直接使用Sklearn中的内置函数来进行实现，另外工具内含一些数据，比如鸢尾花数据和房价预测的数据。</p>
<p>最后如何学习 Sklearn呢？正式前文所写，官方文档是最适合的。但是如果觉得没有头绪的话可以有如下几个方法</p>
<ul>
<li>从具体的实战中学习所使用到的算法，使用倒推的形式来学习Sklearn工具（这种方法适用于我现在的学习方式，等到kaggle的实战课程全部结束之后使用方法2）</li>
<li>直接看文档，将所有的有关算法进行实现</li>
<li>看视频教程或者书进行补充和强化训练，以此加强对sklearn的理解，不管怎么样最重要的还算代码能力。</li>
</ul>
<p><strong>参考文章</strong>：</p>
<ul>
<li><a href="https://blog.csdn.net/lbship/article/details/81701650" target="_blank" rel="noopener">Sklearn 入门，把各个机器学习用法用一遍原来这么简单</a></li>
</ul>
<h2 id="二、词袋模型"><a href="#二、词袋模型" class="headerlink" title="二、词袋模型"></a>二、词袋模型</h2><p>词袋模型最初被用在信息检索领域，对于一篇文档来说，假定<strong>不考虑文档内的词的顺序关系和语法</strong>，只考虑该文档是否出现过这个词以及所有词的权重。所以词袋模型有很大的局限性，因为它仅仅考虑了词频，没有考虑上下文的关系，因此会丢失一部分文本的语义。</p>
<p>词袋模型首先会进行分词，在分词之后通过统计每个词在文本中出现的次数，我们就得到该文本基于词的特征，如果将各个文本样本的这些词与对应的词频放在一起，就是我们常说的向量化。</p>
<p>词袋模型的三步曲</p>
<ul>
<li>分词 tokenizing</li>
<li>统计修订词特征值 counting</li>
<li>标准化 normalizing</li>
</ul>
<h3 id="2-1-词袋模型在各个领域的使用"><a href="#2-1-词袋模型在各个领域的使用" class="headerlink" title="2.1 词袋模型在各个领域的使用"></a>2.1 词袋模型在各个领域的使用</h3><ol start="0">
<li><p><strong>文本处理领域</strong><br>假设有5类主题，我们的任务是来了一篇文档，判断它属于哪个主题。在训练集中，我们有若干篇文档，它们的主题类型是已知的。我们从中选出一些文档，每篇文档内有一些词，我们利用这些词来构建词袋。我们的词袋可以是这种形式</p>
<blockquote>
<p>{‘watch’,’sports’,’phone’,’like’,’roman’,..}</p>
</blockquote>
<p> 然后每篇文档都可以转化为以各个单词作为横坐标，以单词出现的次数为纵坐标的直方图，如下图所示，之后再进行归一化，将每个词出现的频数作为文档的特征。<br><img src="1.png" alt="词袋模型基本原理"></p>
</li>
<li><p><strong>图像领域</strong><br>如果说文档对应一幅图像的话，那么文档内的词就是一个图像块的特征向量，一篇文档有若干个词构成，同样的，一幅图像由若干个图像块构成，而特征向量是图像块的一种表达方式，我们求的N幅图像块中的若干个图像块的特征向量，使用k-means 算法把它们聚成k类，这样我们的词袋里就有k个词，然后来了一幅图像，看它包含哪些词，包含单词A，就把单词A的频数加1。最后归一化，得到这副图像的BoW表示，假如k=4，每幅图像有8个小块（patch），那么结果可能是这样的：[2,0,4,2],归一化之后为[0.25,0,0.5,0.25]</p>
</li>
<li><p><strong>语音识别领域</strong><br>假设一段语音信号有2秒长，我们取每帧长40ms，帧移10ms，就可以得到一小段的语音信号，然后提取每一小段上的音频特征，假设这里使用12维MFCC，那么有多少小段语音信号，就有多少个MFCC特征向量。我们的目标是通过一段语音信号，判断它的情感类别。我们的做法是：取一定数量的MFCC特征向量，将他们聚成k个类，那么这里的词袋李的词就是个类别。对于一段语音信号，我们对其进行分段之后，将各小段分配到这k个类别上，那么每个类别就对应了这一段语音信号里属于该类的段的个数，最后归一化，得到其特征表示。</p>
</li>
</ol>
<p><strong>下文只讨论Bow在词袋模型的处理方法</strong></p>
<h3 id="2-2-Sklearn-BoW-的使用方法"><a href="#2-2-Sklearn-BoW-的使用方法" class="headerlink" title="2.2 Sklearn-BoW 的使用方法"></a>2.2 Sklearn-BoW 的使用方法</h3><p>在词袋模型统计词频的时候，可以使用 sklearn 中的 CounntVectorizer 来完成.如果只是为了可以让算法识别文本的话而进行向量化，那么到了<code>X变量</code>这一步就已经完了。后续的测试集和验证集直接调用<code>fit_transform()</code>即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">vectorizer = CountVectorizer(min_df=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 查看参数值 </span></span><br><span class="line">print(vectorizer)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">CountVectorizer(analyzer='word', binary=False, decode_error='strict',</span></span><br><span class="line"><span class="string">        dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content',</span></span><br><span class="line"><span class="string">        lowercase=True, max_df=1.0, max_features=None, min_df=1,</span></span><br><span class="line"><span class="string">        ngram_range=(1, 1), preprocessor=None, stop_words=None,</span></span><br><span class="line"><span class="string">        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',</span></span><br><span class="line"><span class="string">        tokenizer=None, vocabulary=None)</span></span><br><span class="line"><span class="string">在kaggle 电影评论情感分析中我们使用到了</span></span><br><span class="line"><span class="string">- analyzer = 'word'</span></span><br><span class="line"><span class="string">- max_features = 150000 词库最大词数量</span></span><br><span class="line"><span class="string">- stop_words = 导入处理后的停用词列表</span></span><br><span class="line"><span class="string">- ngram_range=(1,4)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 导入待处理的文本列表</span></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">'This  is the first document'</span> ,</span><br><span class="line">    <span class="string">'This is the second second document'</span>,</span><br><span class="line">    <span class="string">'And the thrid one'</span>,</span><br><span class="line">    <span class="string">'Is this the first documen?'</span>,</span><br><span class="line">]</span><br><span class="line">X = vectorizer.fit_transform(corpus)<span class="comment"># fit_transform 统计各个词语出现的次数</span></span><br><span class="line">print(X)</span><br><span class="line"><span class="comment"># 输出中 左边第一个数字是文本的序号 </span></span><br><span class="line"><span class="comment"># 第二个数字是词的序号 该词的序号是基于所有文档的  即后续输出的featre_name</span></span><br><span class="line"><span class="comment"># 第三个数字就是我们的词频</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  (0, 2)	1</span></span><br><span class="line"><span class="string">  (0, 3)	1</span></span><br><span class="line"><span class="string">  (0, 7)	1</span></span><br><span class="line"><span class="string">  (0, 4)	1</span></span><br><span class="line"><span class="string">  (0, 8)	1</span></span><br><span class="line"><span class="string">  (1, 6)	2</span></span><br><span class="line"><span class="string">  (1, 2)	1</span></span><br><span class="line"><span class="string">  (1, 7)	1</span></span><br><span class="line"><span class="string">  (1, 4)	1</span></span><br><span class="line"><span class="string">  (1, 8)	1</span></span><br><span class="line"><span class="string">  (2, 5)	1</span></span><br><span class="line"><span class="string">  (2, 9)	1</span></span><br><span class="line"><span class="string">  (2, 0)	1</span></span><br><span class="line"><span class="string">  (2, 7)	1</span></span><br><span class="line"><span class="string">  (3, 1)	1</span></span><br><span class="line"><span class="string">  (3, 3)	1</span></span><br><span class="line"><span class="string">  (3, 7)	1</span></span><br><span class="line"><span class="string">  (3, 4)	1</span></span><br><span class="line"><span class="string">  (3, 8)	1</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">feature_name = vectorizer.get_feature_names()</span><br><span class="line"><span class="comment"># get_feature_names 可获取词袋中所有文本的关键词</span></span><br><span class="line">print(feature_name)</span><br><span class="line"><span class="comment">#['and', 'documen', 'document', 'first', 'is', 'one', 'second', 'the', 'this', 'thrid']</span></span><br><span class="line"></span><br><span class="line">print(X.toarray())</span><br><span class="line"><span class="comment"># 通过toarry查看词频矩阵的结果</span></span><br><span class="line"><span class="comment"># 由于大部分文本都只会用词汇表中很少一部分的词，因此词向量中有大量的0</span></span><br><span class="line"><span class="comment"># 即稀疏矩阵</span></span><br><span class="line">[[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]]</span><br></pre></td></tr></table></figure>

<p>官方案例中并没有对 <code>CountVectorizer()</code>的具体参数进行描述，这里附上一篇文章: <a href="https://blog.csdn.net/weixin_38278334/article/details/82320307" target="_blank" rel="noopener">Sklearn - CountVetorizer详解</a>。</p>
<p>一般要设置的参数是：ngram_range，max_df,min_df,max_features 等，之前的kaggle比赛中我们就使用了：</p>
<ul>
<li>analyzer = ‘word’</li>
<li>max_features = 150000 词库最大词数量</li>
<li>stop_words = 导入处理后的停用词列表</li>
<li>ngram_range=(1,4)</li>
</ul>
<p>这里将如下函数参数作用进行列举：</p>
<table>
<thead>
<tr>
<th>参数表</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>analyzer</td>
<td>一般使用默认，设置为string类型，如‘word’，‘char’，‘char_wb’，还可以设置为 callable类型</td>
</tr>
<tr>
<td>max_features</td>
<td>默认为None，可设为int，对所有关键词进行降序排序，只取前max_features 个作为关键词集</td>
</tr>
<tr>
<td>stop_words</td>
<td>设置停用词，设为english将使用内置的英语停用词，设为一个list可自定义停用词，设为None不使用停用词，设为None且max_df ∈ [0.7,1.0]将自动根据当前的语料库建立停用词表</td>
</tr>
<tr>
<td>ngram_range</td>
<td>词组切分的长度范围，进行字符串的前后组合，构建出新的词袋标签。<a href="http://www.mamicode.com/info-detail-2599196.html" target="_blank" rel="noopener">参考文章</a></td>
</tr>
<tr>
<td>max_df</td>
<td>可以设置为范围在[0.0 1.0]的float，也可以设置为没有范围限制的int，默认为1.0。这个参数的作用是作为一个阈值，当构造语料库的关键词集的时候，如果某个词的document frequence大于max_df，这个词不会被当作关键词。如果这个参数是float，则表示词出现的次数与语料库文档数的百分比，如果是int，则表示词出现的次数。如果参数中已经给定了vocabulary，则这个参数无效</td>
</tr>
<tr>
<td>min_df</td>
<td>类似于max_df，不同之处在于如果某个词的document frequence小于min_df，则这个词不会被当作关键词</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>属性表</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>vocabulary_</td>
<td>词汇表；字典型</td>
</tr>
<tr>
<td>get_feature_names()</td>
<td>所有文本的词汇；列表型</td>
</tr>
<tr>
<td>stop_words_</td>
<td>返回停用词表</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>方法表</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>fit_transform(X)</td>
<td>拟合模型，并返回文本矩阵</td>
</tr>
<tr>
<td>fit()</td>
<td>对于一个由字符粗构成的数组，每个元素可能是一个以空格分割的句子，使用该函数可以将它们分隔，为每一个单词编码，在这个过程中自动滤除停止词</td>
</tr>
<tr>
<td>transform()</td>
<td>将输入的数组中的每个元素进行分隔，然后使用fit()中生产的编码字典，将原单词转化成编码，数据以<code>csr_matrix</code>的形式返回</td>
</tr>
</tbody></table>
<p>具体的使用方法可以参考：<a href="https://afrunk.github.io/2019/07/23/kaggle-movie-reviews/">Kaggle-Sentiment Analysis on Moview Reviews</a></p>
<ul>
<li>对于方法表最直观的解释就是使用<code>fit_transform()</code> 或<code>fit()</code>函数可以直接得到一个矩阵，这个一般是为做语料库时使用。</li>
<li>如果是训练集数据或者验证集数据则需要首先使用 <code>transform()</code> 然后再 <code>fit()</code></li>
<li><a href="https://blog.csdn.net/songbinxu/article/details/80366950" target="_blank" rel="noopener">自己实现一个 CountVectorizer</a></li>
</ul>
<h2 id="三、TF-IDF"><a href="#三、TF-IDF" class="headerlink" title="三、TF-IDF"></a>三、TF-IDF</h2><p>有些词在文本中尽管词频高，但是却不重要，这时我们考虑使用TF-IDF技术。</p>
<p>TF-IDF(Teram Frequency-Inverse Document Frequency)是一种用于资讯检索与文本挖掘的常用加权技术。TF-IDF是一种统计方法，用以评估一个字词对于一个文件集或一个语料库中的其中一份文件的重要性。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。<br>TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF实际上是：TF * IDF。<br>（1）词频（Teram Frequency，TF）指的是某一个给定的词语在该文件中出现的频率。即词w在文档d中出现的次数count(w, d)和文档d中总词数size(d)的比值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf(w,d) = count(w, d) / size(d)</span><br></pre></td></tr></table></figure>

<p>这个数字是对词数 (term count) 的归一化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词数，而不管该词语重要与否。）</p>
<p>（2）逆向文件频率（Inverse Document Frequency，IDF）是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。即文档总数n与词w所出现文件数docs(w, D)比值的对数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">idf = log(n / docs(w, D))</span><br></pre></td></tr></table></figure>

<p>TF-IDF根据 tf 和 idf 为每一个文档d和由关键词w[1]…w[k]组成的查询串q计算一个权值，用于表示查询串q与文档d的匹配度：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf-idf(q, d) = sum &#123; i = 1..k | tf-idf(w[i], d) &#125; = sum &#123; i = 1..k | tf(w[i], d) * idf(w[i]) &#125;</span><br></pre></td></tr></table></figure>

<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。</p>
<h3 id="3-1-Sklearn-TF-IDF-的使用方法"><a href="#3-1-Sklearn-TF-IDF-的使用方法" class="headerlink" title="3.1 Sklearn-TF-IDF 的使用方法"></a>3.1 Sklearn-TF-IDF 的使用方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">tfidf2 = TfidfVectorizer()</span><br><span class="line">re = tfidf2.fit_transform(corpus)</span><br><span class="line"><span class="keyword">print</span> (re)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">  (0, 8)	0.4181266243877562</span></span><br><span class="line"><span class="string">  (0, 4)	0.4181266243877562</span></span><br><span class="line"><span class="string">  (0, 7)	0.3418459132932508</span></span><br><span class="line"><span class="string">  (0, 3)	0.5164695651831305</span></span><br><span class="line"><span class="string">  (0, 2)	0.5164695651831305</span></span><br><span class="line"><span class="string">  (1, 8)	0.2671444810352856</span></span><br><span class="line"><span class="string">  (1, 4)	0.2671444810352856</span></span><br><span class="line"><span class="string">  (1, 7)	0.2184081179582327</span></span><br><span class="line"><span class="string">  (1, 2)	0.329976581049803</span></span><br><span class="line"><span class="string">  (1, 6)	0.8370669044188771</span></span><br><span class="line"><span class="string">  (2, 7)	0.2884767487500274</span></span><br><span class="line"><span class="string">  (2, 0)	0.5528053199908667</span></span><br><span class="line"><span class="string">  (2, 9)	0.5528053199908667</span></span><br><span class="line"><span class="string">  (2, 5)	0.5528053199908667</span></span><br><span class="line"><span class="string">  (3, 8)	0.3878225151467608</span></span><br><span class="line"><span class="string">  (3, 4)	0.3878225151467608</span></span><br><span class="line"><span class="string">  (3, 7)	0.3170703183040649</span></span><br><span class="line"><span class="string">  (3, 3)	0.4790379614294201</span></span><br><span class="line"><span class="string">  (3, 1)	0.6075989123184679</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>

<p>使用方法与 BoW的类似，这里不再赘述，详情可以参考：<a href="http://afrunk.github.io/2019/07/23/kaggle-movie-reviews/">Kaggle-Sentiment Analysis on Moview Reviews</a></p>

      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://afrunk.github.io">Afrunk</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://afrunk.github.io/2019/07/23/The-Bag-of-Words/">http://afrunk.github.io/2019/07/23/The-Bag-of-Words/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/Machine-Learning/">Machine Learning</a>
            <a href="/tags/Sklearn/">Sklearn</a>
            </div>
        
        <nav class="post-nav"><a class="next" href="/2019/07/23/Simiki operates on documents/">
        <span class="next-text nav-default">Simiki operates on documents</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:afrunk7@gmail.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/afrunk" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Afrunk</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
